{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKuPS2PwF1HZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((120,120)),\n",
        "    transforms.CenterCrop((110,110)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "                                 ])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='data', train=True, transform=transforms, download=True)\n",
        "testset = datasets.CIFAR10(root='data', train=False, transform=transforms, download=True)\n",
        "\n",
        "dataset_len = len(trainset)\n",
        "indices = list(range(dataset_len))\n",
        "len_trainset = int(dataset_len * 0.8)\n",
        "\n",
        "train_idx = torch.utils.data.SubsetRandomSampler(indices[:len_trainset])\n",
        "validation_idx = torch.utils.data.SubsetRandomSampler(indices[len_trainset:])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_idx)\n",
        "validationloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=validation_idx)\n",
        "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n",
        "           'ship', 'truck']\n",
        "\n",
        "for images, labels in trainloader:\n",
        "  print('Image batch dimensions:', images.shape)\n",
        "  print('Label batch dimensions:', labels.shape)\n",
        "  print('Class labels of 10 examples:', labels[:10])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP3geiN7fvQl"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import non_deterministic\n",
        "import torch.nn as nn\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, \n",
        "                         padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "  \n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion: int = 1\n",
        "\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
        "               groups=1, base_width=64, dilation=1, norm_layer=None):\n",
        "    \n",
        "    super().__init__()\n",
        "    if norm_layer is None:\n",
        "      norm_layer = nn.BatchNorm2d\n",
        "    if groups != 1 or base_width != 64:\n",
        "      raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "    if dilation > 1:\n",
        "      raise NotImplementedError('Dilation > 1 not supported by BasicBlock')\n",
        "\n",
        "    self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "    self.bn1 = norm_layer(planes)\n",
        "    self.relu = nn.ReLU(inplace=True) \n",
        "    self.conv2 = conv3x3(planes, planes)\n",
        "    self.bn2 = norm_layer(planes)\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(x)\n",
        "\n",
        "    out += identity\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out\n",
        "  \n",
        "class Bottleneck(torch.nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "\n",
        "      super.__init__()\n",
        "      if norm_layer is None:\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "\n",
        "      width = int(planes * (base_width / 64.)) * groups \n",
        "      self.conv1 = conv1x1(inplanes, width)\n",
        "      self.bn1 = norm_layer(width)\n",
        "      self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "      self.bn2 = norm_layer(width)\n",
        "      self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "      self.bn3 = norm_layer(planes * self.expansion)\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "      self.downsample = downsample\n",
        "      self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "      identity = x\n",
        "\n",
        "      out = self.conv1(x)\n",
        "      out = self.bn1(out)\n",
        "      out = self.relu(out)\n",
        "\n",
        "      out = self.conv2(out)\n",
        "      out = self.bn2(out)\n",
        "      out = self.relu(out)\n",
        "\n",
        "      out = self.conv3(out)\n",
        "      out = self.bn3(out)\n",
        "\n",
        "      if self.downsample is not None:\n",
        "        identity = self.downsample(x)\n",
        "\n",
        "      out += identity\n",
        "      out = self.relu(out)\n",
        "\n",
        "      return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "  def __init__(self, block, layers, num_classes, zero_init_residual=False, groups=1,\n",
        "               width_per_group=64, replace_stride_with_dilation=None, norm_layer=None):\n",
        "    \n",
        "    super().__init__()\n",
        "    if norm_layer is None:\n",
        "      norm_layer = nn.BatchNorm2d\n",
        "    self.norm_layer = norm_layer\n",
        "\n",
        "    self.inplanes = 64\n",
        "    self.dilation = 1\n",
        "    if replace_stride_with_dilation is None:\n",
        "      replace_stride_with_dilation = [False, False, False]\n",
        "    if len(replace_stride_with_dilation) != 3:\n",
        "      raise ValueError('replace_stride_with_value should be None or a 3-element tuple')\n",
        "\n",
        "    self.groups = groups\n",
        "    self.base_width = width_per_group\n",
        "    self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                           bias=False)\n",
        "    self.bn1 = norm_layer(self.inplanes)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.layer1 = self.make_layer_(block, 64, layers[0])\n",
        "    self.layer2 = self.make_layer_(block, 128, layers[1], stride=2,\n",
        "                                   dilate=replace_stride_with_dilation[0])\n",
        "    self.layer3 = self.make_layer_(block, 256, layers[2], stride=2, \n",
        "                                   dilate=replace_stride_with_dilation[1])\n",
        "    self.layer4 = self.make_layer_(block, 512, layers[3], stride=2,\n",
        "                                   dilate=replace_stride_with_dilation[2])\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes) \n",
        "\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity='relu')\n",
        "      elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    if zero_init_residual:\n",
        "      for m in self.modules():\n",
        "        if isinstance(m, Bottleneck):\n",
        "          nn.init.constant_(m.bn3.weight, 0) \n",
        "        elif isinstance(m, BasicBlock):\n",
        "          nn.init.constant_(m.bn2.weight, 0) \n",
        "\n",
        "  def make_layer_(self, block, planes, blocks, stride=1, dilate=False):\n",
        "    norm_layer = self.norm_layer\n",
        "    downsample = None\n",
        "    previous_dilation = self.dilation\n",
        "    if dilate:\n",
        "      self.dilation *= stride\n",
        "      stride = 1\n",
        "    if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "      downsample = nn.Sequential(\n",
        "          conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "          norm_layer(planes * block.expansion)\n",
        "      )\n",
        "\n",
        "    layers = []\n",
        "    layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                        self.base_width, previous_dilation, norm_layer))\n",
        "    self.inplanes = planes * block.expansion\n",
        "    for _ in range(1, blocks):\n",
        "      layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                          base_width=self.base_width, dilation=self.dilation,\n",
        "                          norm_layer=norm_layer))\n",
        "    \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SEIWBiw78MZ"
      },
      "outputs": [],
      "source": [
        "model = ResNet(BasicBlock, layers=[2,2,2,2], num_classes=10)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8uc_XHm6Tpq"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "  with torch.no_grad():\n",
        "\n",
        "    correct_pred, num_examples = 0, 0\n",
        "\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "      features = features\n",
        "      targets = targets.float()\n",
        "\n",
        "      logits = model(features)\n",
        "      _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "      num_examples += targets.size(0)\n",
        "      correct_pred += (predicted_labels == targets).sum()\n",
        "  \n",
        "  return correct_pred.float()/num_examples * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKGNOudYBfYh"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs, train_loader, valid_loader, test_loader,\n",
        "                optimizer, logging_interval=50, scheduler=None, \n",
        "                scheduler_on='valid_acc'):\n",
        "  \n",
        "  start_time = time.time()\n",
        "  minibatch_loss_list, train_acc_list, valid_acc_list = [], [], []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "        logits = model(features)\n",
        "        loss = nn.functional.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        minibatch_loss_list.append(loss.item())\n",
        "        if not batch_idx % logging_interval:\n",
        "          print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                      f'| Batch {batch_idx:04d}/{len(train_loader):04d} '\n",
        "                      f'| Loss: {loss:.4f}')\n",
        "        \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      train_acc = compute_accuracy(model, train_loader)\n",
        "      valid_acc = compute_accuracy(model, valid_loader)\n",
        "      print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                  f'| Train: {train_acc :.2f}% '\n",
        "                  f'| Validation: {valid_acc :.2f}%')\n",
        "      train_acc_list.append(train_acc.item())\n",
        "      valid_acc_list.append(valid_acc.item())\n",
        "\n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Time elapsed: {elapsed:.2f} min')\n",
        "\n",
        "    if scheduler is not None:\n",
        "       if scheduler_on == 'valid_acc':\n",
        "         scheduler.step(valid_acc_list[-1])\n",
        "       elif scheduler_on == 'minibatch_loss':\n",
        "        scheduler.step(minibatch_loss_list[-1])\n",
        "       else:\n",
        "        raise ValueError(f'Invalid `scheduler_on choice`')\n",
        "    \n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Total Training Time: {elapsed:.2f} min')\n",
        "\n",
        "    test_acc = compute_accuracy(model, test_loader)\n",
        "    print(f'Test accuracy {test_acc:.2f}%')\n",
        "\n",
        "    return minibatch_loss_list, train_acc_list, valid_acc_list    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvC5LQQptYGq"
      },
      "outputs": [],
      "source": [
        "def plot_training_loss(minibatch_loss_list, num_epochs, iter_per_epoch,\n",
        "                       results_dir=None, averaging_iterations=100):\n",
        "\n",
        "    plt.figure()\n",
        "    ax1 = plt.subplot(1, 1, 1)\n",
        "    ax1.plot(range(len(minibatch_loss_list)),\n",
        "             (minibatch_loss_list), label='Minibatch Loss')\n",
        "\n",
        "    if len(minibatch_loss_list) > 1000:\n",
        "        ax1.set_ylim([\n",
        "            0, np.max(minibatch_loss_list[1000:])*1.5\n",
        "            ])\n",
        "    ax1.set_xlabel('Iterations')\n",
        "    ax1.set_ylabel('Loss')\n",
        "\n",
        "    ax1.plot(np.convolve(minibatch_loss_list,\n",
        "                         np.ones(averaging_iterations,)/averaging_iterations,\n",
        "                         mode='valid'),\n",
        "             label='Running Average')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2 = ax1.twiny()\n",
        "    newlabel = list(range(num_epochs+1))\n",
        "\n",
        "    newpos = [e*iter_per_epoch for e in newlabel]\n",
        "\n",
        "    ax2.set_xticks(newpos[::10])\n",
        "    ax2.set_xticklabels(newlabel[::10])\n",
        "\n",
        "    ax2.xaxis.set_ticks_position('bottom')\n",
        "    ax2.xaxis.set_label_position('bottom')\n",
        "    ax2.spines['bottom'].set_position(('outward', 45))\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_xlim(ax1.get_xlim())\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if results_dir is not None:\n",
        "        image_path = os.path.join(results_dir, 'plot_training_loss.pdf')\n",
        "        plt.savefig(image_path)\n",
        "\n",
        "\n",
        "def plot_accuracy(train_acc_list, valid_acc_list, results_dir):\n",
        "\n",
        "    num_epochs = len(train_acc_list)\n",
        "\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             train_acc_list, label='Training')\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             valid_acc_list, label='Validation')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if results_dir is not None:\n",
        "        image_path = os.path.join(\n",
        "            results_dir, 'plot_acc_training_validation.pdf')\n",
        "        plt.savefig(image_path)\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(conf_mat,\n",
        "                          hide_spines=False,\n",
        "                          hide_ticks=False,\n",
        "                          figsize=None,\n",
        "                          cmap=None,\n",
        "                          colorbar=False,\n",
        "                          show_absolute=True,\n",
        "                          show_normed=False,\n",
        "                          class_names=None):\n",
        "\n",
        "    if not (show_absolute or show_normed):\n",
        "        raise AssertionError('Both show_absolute and show_normed are False')\n",
        "    if class_names is not None and len(class_names) != len(conf_mat):\n",
        "        raise AssertionError('len(class_names) should be equal to number of'\n",
        "                             'classes in the dataset')\n",
        "\n",
        "    total_samples = conf_mat.sum(axis=1)[:, np.newaxis]\n",
        "    normed_conf_mat = conf_mat.astype('float') / total_samples\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ax.grid(False)\n",
        "    if cmap is None:\n",
        "        cmap = plt.cm.Blues\n",
        "\n",
        "    if figsize is None:\n",
        "        figsize = (len(conf_mat)*1.25, len(conf_mat)*1.25)\n",
        "\n",
        "    if show_normed:\n",
        "        matshow = ax.matshow(normed_conf_mat, cmap=cmap)\n",
        "    else:\n",
        "        matshow = ax.matshow(conf_mat, cmap=cmap)\n",
        "\n",
        "    if colorbar:\n",
        "        fig.colorbar(matshow)\n",
        "\n",
        "    for i in range(conf_mat.shape[0]):\n",
        "        for j in range(conf_mat.shape[1]):\n",
        "            cell_text = \"\"\n",
        "            if show_absolute:\n",
        "                cell_text += format(conf_mat[i, j], 'd')\n",
        "                if show_normed:\n",
        "                    cell_text += \"\\n\" + '('\n",
        "                    cell_text += format(normed_conf_mat[i, j], '.2f') + ')'\n",
        "            else:\n",
        "                cell_text += format(normed_conf_mat[i, j], '.2f')\n",
        "            ax.text(x=j,\n",
        "                    y=i,\n",
        "                    s=cell_text,\n",
        "                    va='center',\n",
        "                    ha='center',\n",
        "                    color=\"white\" if normed_conf_mat[i, j] > 0.5 else \"black\")\n",
        "    \n",
        "    if class_names is not None:\n",
        "        tick_marks = np.arange(len(class_names))\n",
        "        plt.xticks(tick_marks, class_names, rotation=90)\n",
        "        plt.yticks(tick_marks, class_names)\n",
        "        \n",
        "    if hide_spines:\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['left'].set_visible(False)\n",
        "        ax.spines['bottom'].set_visible(False)\n",
        "    ax.yaxis.set_ticks_position('left')\n",
        "    ax.xaxis.set_ticks_position('bottom')\n",
        "    if hide_ticks:\n",
        "        ax.axes.get_yaxis().set_ticks([])\n",
        "        ax.axes.get_xaxis().set_ticks([])\n",
        "\n",
        "    plt.xlabel('predicted label')\n",
        "    plt.ylabel('true label')\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMUevskBy9_H"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       factor=0.1,\n",
        "                                                       mode='max',\n",
        "                                                       verbose=True)\n",
        "\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N8UZjPYV0q8Q"
      },
      "outputs": [],
      "source": [
        "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
        "    model=model,\n",
        "    num_epochs=num_epochs,\n",
        "    train_loader=trainloader,\n",
        "    valid_loader=validationloader,\n",
        "    test_loader=testloader,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    scheduler_on='valid_acc',\n",
        "    logging_interval=10)\n",
        "\n",
        "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
        "                   num_epochs=num_epochs,\n",
        "                   iter_per_epoch=len(trainloader),\n",
        "                   results_dir=None,\n",
        "                   averaging_iterations=200)\n",
        "plt.show()\n",
        "\n",
        "plot_accuracy(train_acc_list=train_acc_list,\n",
        "              valid_acc_list=valid_acc_list,\n",
        "              results_dir=None)\n",
        "plt.ylim([60, 100])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyOqjWJXn0i8iObQh1CVIOf4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}